{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25dc1d67",
   "metadata": {},
   "source": [
    "# SAT Semantic Mapping for Classification\n",
    "\n",
    "The SAT mapping classification process is as follows:\n",
    "\n",
    "1. A similarity matrix is built with SAT segments in rows and segments for classification is columns. The cell values contain the semantic similarity of a segment-segment pair computed from the segment encoding vectors.\n",
    "2. A threshold is applied to the matrix and the indices of columns containing above-threshold cell values are collected. \n",
    "3. The column indices are considered as those segments classified by the SAT.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabbf727",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__      = 'Roy Gardner'\n",
    "\n",
    "%run ./_library/packages.py\n",
    "\n",
    "def do_load(model_path,exclusion_list=[],verbose=True):\n",
    "    if verbose:\n",
    "        print('Loading model…')\n",
    "    model_dict = {}\n",
    "\n",
    "    _, _, files = next(os.walk(model_path))\n",
    "    files = [f for f in files if f.endswith('.json') and not f in exclusion_list]\n",
    "    for file in files:\n",
    "        model_name = os.path.splitext(file)[0]\n",
    "        with open(model_path + file, 'r', encoding='utf-8') as f:\n",
    "            model_dict[model_name] = json.load(f)\n",
    "            f.close() \n",
    "    if verbose:\n",
    "        print('Finished loading model.')\n",
    "    return model_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe638b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ce3de6f",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2addb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../../model/'\n",
    "\n",
    "model_dict = do_load(model_path,exclusion_list=[],verbose=True)\n",
    "\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d30239c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e326282e",
   "metadata": {},
   "source": [
    "## Build a SAT-segments similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7597e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SAT topic\n",
    "sat_topic = 'equalgr5'\n",
    "\n",
    "print('Selected SAT:',sat_topic)\n",
    "\n",
    "# Get the encoding vectors for the SAT\n",
    "sat_segment_ids =  model_dict['sat_segments_dict'][sat_topic]\n",
    "sat_segment_indices =  [model_dict['encoded_segments'].index(segment_id) for segment_id in sat_segment_ids]\n",
    "sat_encodings = [model_dict['segment_encodings'][index] for index in sat_segment_indices]\n",
    "\n",
    "print('Number of segments in SAT:',len(sat_segment_ids))\n",
    "print()\n",
    "\n",
    "# Build a similarity matrix with SAT segments in rows and corpus segments in columns\n",
    "print('Building matrix…')\n",
    "sim_matrix = cdist(sat_encodings,model_dict['segment_encodings'],ad.angular_distance)\n",
    "print('Similarity matrix dimensions:',sim_matrix.shape)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c8c3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a903e7a",
   "metadata": {},
   "source": [
    "## Find above threshold column segments in the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757ace5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a semantic similarity threshold\n",
    "threshold = 0.74\n",
    "\n",
    "# Threshold the matrix and return cell indices containing above threshold values\n",
    "indices = np.where(sim_matrix >= threshold)\n",
    "\n",
    "# Get the IDs of above threshold column segments. We use the set of column indices to remove duplicates.\n",
    "classified_segment_ids = [model_dict['encoded_segments'][index] for index in set(indices[1])]\n",
    "\n",
    "# In this example our columns contain the SAT segments so we need to remove these.\n",
    "# This won't be the case in real world scenarios where the segments to classify are unknown.\n",
    "classified_segment_ids = set(classified_segment_ids).difference(set(sat_segment_ids))\n",
    "print('Number of classified segments not in the SAT:',len(classified_segment_ids))\n",
    "print()\n",
    "\n",
    "# Display the classified segments\n",
    "for segment_id in classified_segment_ids:\n",
    "    segment_text = model_dict['segments_dict'][segment_id]['text']\n",
    "    print(segment_id,segment_text)\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae28bd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb90425c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
